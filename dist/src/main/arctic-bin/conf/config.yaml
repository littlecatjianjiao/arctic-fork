ams:
  admin-username: admin
  admin-password: admin
  server-bind-host: "0.0.0.0"
  server-expose-host: "127.0.0.1"
  refresh-external-catalog-interval: 180000 # 3min
  refresh-table-thread-count: 10
  refresh-table-interval: 60000 #1min
  expire-table-thread-count: 10
  clean-orphan-file-thread-count: 10
  sync-hive-tables-thread-count: 10

  blocker:
    timeout: 60000 # 1min

  thrift-server:
    bind-port: 1260
    max-message-size: 104857600 # 100MB
    worker-thread-count: 20
    selector-thread-count: 2
    selector-queue-size: 4

  http-server:
    bind-port: 1630

  self-optimizing:
    commit-thread-count: 10

  database:
    type: derby
    jdbc-driver-class: org.apache.derby.jdbc.EmbeddedDriver
    url: jdbc:derby:/tmp/arctic/derby;create=true

  #  MySQL database configuration.
  #  database:
  #    type: mysql
  #    jdbc-driver-class: com.mysql.cj.jdbc.Driver
  #    url: jdbc:mysql://127.0.0.1:3306?useUnicode=true&characterEncoding=UTF8&autoReconnect=true&useAffectedRows=true&useSSL=false
  #    username: root
  #    password: root

  terminal:
    backend: local
    local.spark.sql.session.timeZone: UTC
    local.spark.sql.iceberg.handle-timestamp-without-timezone: false

#  Kyuubi terminal backend configuration.
#  terminal:
#    backend: kyuubi
#    kyuubi.jdbc.url: jdbc:hive2://127.0.0.1:10009/


#  High availability configuration.
#  ha:
#    enabled: true
#    cluster-name: default
#    zookeeper-address: 127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183

containers:
  - name: localContainer
    container-impl: com.netease.arctic.optimizer.LocalOptimizerContainer
    properties:
      export.JAVA_HOME: "/opt/java"   # JDK environment

#containers:
#  - name: flinkContainer
#    container-impl: com.netease.arctic.optimizer.FlinkOptimizerContainer
#    properties:
#      flink-home: "/opt/flink/"                                     # Flink install home
#      export.JVM_ARGS: "-Djava.security.krb5.conf=/opt/krb5.conf"   # Flink launch jvm args, like kerberos config when ues kerberos
#      export.HADOOP_CONF_DIR: "/etc/hadoop/conf/"                   # Hadoop config dir
#      export.HADOOP_USER_NAME: "hadoop"                             # Hadoop user submit on yarn
#      export.FLINK_CONF_DIR: "/etc/hadoop/conf/"                    # Flink config dir

optimizer_groups:
  - name: default
    container: localContainer
    properties:
      memory: "1024" # The size of memory allocated for each parallel

  - name: external-group
    container: external # The external container is used to host all externally launched optimizers.

#  - name: flinkGroup
#    container: flinkContainer
#    properties:
#      taskmanager.memory: "2048"
#      jobmanager.memory: "1024"